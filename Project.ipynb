{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfh3JsCO8JKBUUMq5WyIgu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/orevs-com/Stock-Market-Price-Prediction/blob/main/Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "V8zfClC4RtzD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Enhanced Stock Price Prediction Using LSTM with Technical Indicators: A Comparative Study with XGBoost and ARIMA\n",
        "\n",
        "# by Orevaoghene Otiede"
      ],
      "metadata": {
        "id": "WC1ufaXavhsS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the required libraries for the project\n"
      ],
      "metadata": {
        "id": "ltjuMkQJv6Gx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install pandas_ta\n",
        "!pip install pandas_ta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtdIHgN4PIOc",
        "outputId": "5921dca2-93ce-4c1c-8211-bd9dd3fa9729"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas_ta in /usr/local/lib/python3.11/dist-packages (0.3.14b0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from pandas_ta) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->pandas_ta) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->pandas_ta) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->pandas_ta) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->pandas_ta) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->pandas_ta) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Corrcting the numpy import for pandas_ta\n",
        "path = \"/usr/local/lib/python3.11/dist-packages/pandas_ta/momentum/squeeze_pro.py\"\n",
        "\n",
        "# Read the file and replace the line\n",
        "with open(path, 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Replace the incorrect import\n",
        "content = content.replace(\"from numpy import NaN as npNaN\", \"from numpy import nan as npNaN\")\n",
        "\n",
        "# Write the updated content back\n",
        "with open(path, 'w') as file:\n",
        "    file.write(content)\n",
        "\n",
        "print(\"File updated successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JTkWLG1PjRE",
        "outputId": "c72d3c74-c9d4-4eeb-ec1a-7f8107d42a7c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File updated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandas_ta as ta\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn import linear_model\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import keras.backend as K\n",
        "import yfinance as yf\n",
        "import os"
      ],
      "metadata": {
        "id": "YxI-S3pDwFZV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the drive module from the google.colab package.\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount the Google Drive to the specified mount point in the Colab environment.\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "G1O2owTDPbuS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54270dff-34d5-483e-95cc-e2642c7f759e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "List of ticker symbols for Training Companies"
      ],
      "metadata": {
        "id": "UENSEN76WMjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of Ticker Symbols\n",
        "train_tickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'NVDA', 'META']\n",
        "test_tickers = ['TSLA', 'AVGO', 'COST', 'NFLX', 'ADBE', 'INTC']"
      ],
      "metadata": {
        "id": "-XEBSgMHWqas"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading and Saving the Stock Market Price Data"
      ],
      "metadata": {
        "id": "XzQ0BF2Vycvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the date range\n",
        "start_date = \"2015-01-01\"\n",
        "end_date = \"2024-12-31\"\n",
        "# Define the file path\n",
        "drive_path = '/content/drive/MyDrive/Colab Notebooks/Stock Market Data/'\n",
        "\n",
        "# Function to download and save data for a list of tickers\n",
        "def download_and_save_tickers(tickers, start, end, base_path):\n",
        "    for ticker in tickers:\n",
        "        try:\n",
        "            # Dwonload data from Yahoo Finance with auto adjusted closed price\n",
        "            df = yf.download(ticker, start=start, end=end, interval=\"1d\",\n",
        "                             auto_adjust=True)\n",
        "\n",
        "            if not df.empty:\n",
        "                file_path = os.path.join(base_path, f\"{ticker}.csv\")\n",
        "                df.to_csv(file_path)\n",
        "                print(f\"Successfully downloaded and saved data for {ticker}\")\n",
        "            else:\n",
        "                print(f\"No data found for {ticker} in the specified date range.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error downloading data for {ticker}: {e}\")\n",
        "\n",
        "# Download and save training data\n",
        "download_and_save_tickers(train_tickers, start_date, end_date, drive_path)\n",
        "\n",
        "# Download and save testing data\n",
        "download_and_save_tickers(test_tickers, start_date, end_date, drive_path)\n",
        "\n",
        "print(\"\\nAll data download attempts complete.\")"
      ],
      "metadata": {
        "id": "XhurJAlLzrCC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09f79f36-3a51-496d-facc-3e64da254f99"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded and saved data for AAPL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded and saved data for MSFT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded and saved data for GOOGL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded and saved data for AMZN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded and saved data for NVDA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded and saved data for META\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded and saved data for TSLA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded and saved data for AVGO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded and saved data for COST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded and saved data for NFLX\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded and saved data for ADBE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded and saved data for INTC\n",
            "\n",
            "All data download attempts complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating for Technical Indicators"
      ],
      "metadata": {
        "id": "31sCJm6tPdiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the directory where the stock data CSV files are saved\n",
        "data_dir = '/content/drive/MyDrive/Colab Notebooks/Stock Market Data/'\n",
        "output_dir = '/content/drive/MyDrive/Colab Notebooks/Data with Indicators/'\n",
        "\n",
        "# Create an Output Directory\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Get a list of all CSV files\n",
        "csv_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
        "\n",
        "for file_name in csv_files:\n",
        "    ticker = file_name.replace('.csv', '') # Extract ticker from file name\n",
        "    file_path = os.path.join(data_dir, file_name)\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(file_path, skiprows=3) # Considering Multi Index Rows\n",
        "        df.columns = ['Date', 'Close', 'High', 'Low', 'Open', 'Volume']\n",
        "        df['Date'] = pd.to_datetime(df['Date'])\n",
        "        df.set_index('Date', inplace=True)\n",
        "        print(f\"Calculating indicators for {ticker}...\")\n",
        "\n",
        "        if not all(col in df.columns for col in ['Open', 'High', 'Low', 'Volume']):\n",
        "            print(f\"Skipping {ticker}: Missing OHLCV columns after parsing.\")\n",
        "            continue\n",
        "\n",
        "        # Calculating Technical Indicators using pandas_ta\n",
        "\n",
        "        # Trend Indicators\n",
        "        df.ta.sma(length=200, append=True)\n",
        "        df.ta.sma(length=50, append=True)\n",
        "        df.ta.ema(length=26, append=True)\n",
        "        df.ta.macd(append=True)\n",
        "\n",
        "        # Momentum Indicators\n",
        "        df.ta.rsi(length=14, append=True)\n",
        "        df.ta.willr(append=True)\n",
        "\n",
        "        # Volatility Indicator\n",
        "        df.ta.bbands(append=True)\n",
        "\n",
        "        # Volume Indicator\n",
        "        df.ta.obv(append=True)\n",
        "        df.ta.cmf(append=True)\n",
        "\n",
        "        # Adding Daily Returns and Log Returns\n",
        "        df['Daily_Return'] = df['Close'].pct_change()\n",
        "        df['Log_Return'] = np.log(df['Close'] / df['Close'].shift(1))\n",
        "        df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "        # Add Lagged Features for all calculated indicators\n",
        "\n",
        "        # Columns from SMA (Trend Indicators)\n",
        "        lag_cols = ['SMA_200', 'SMA_50', 'EMA_26']\n",
        "\n",
        "        # Columns from MACD (Trend Indicators)\n",
        "        lag_cols.extend(['MACD_12_26_9', 'MACDh_12_26_9', 'MACDs_12_26_9'])\n",
        "\n",
        "        # Columns from RSI, Williams (Momentum Indicators)\n",
        "        lag_cols.extend(['RSI_14', 'WILLR_14'])\n",
        "\n",
        "        # Columns from Bollinger Bands (Volatiity Indicators)\n",
        "        lag_cols.extend(['BBL_5_2.0', 'BBM_5_2.0', 'BBU_5_2.0', 'BBB_5_2.0', 'BBP_5_2.0'])\n",
        "\n",
        "        # Columns from OBV, CMF (Volume Indicators)\n",
        "        lag_cols.extend(['OBV', 'CMF_20'])\n",
        "\n",
        "        # Columns from Daily Returns and Log Returns\n",
        "        lag_cols.extend(['Daily_Return', 'Log_Return'])\n",
        "\n",
        "        # Apply lagging\n",
        "        for col in lag_cols:\n",
        "            if col in df.columns:\n",
        "                df[f'Lag_{col}'] = df[col].shift(1)\n",
        "            else:\n",
        "                print(f\"  Column '{col}' not found for {ticker} .\")\n",
        "\n",
        "         # Data Cleaning after adding Technical Indicators and Lagged Features\n",
        "        rows = len(df)\n",
        "        df.dropna(inplace=True)\n",
        "        print(f\"  Dropped {rows - len(df)} rows with NaN values for {ticker}.\")\n",
        "\n",
        "        # Save the processed DataFrame to a new CSV\n",
        "        output_file_path = os.path.join(output_dir, f\"{ticker}_indicators.csv\")\n",
        "        df.to_csv(output_file_path)\n",
        "        print(f\"Saved Technical Indicators for {ticker} to {output_file_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {ticker}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uZV2wnrPncq",
        "outputId": "e67f7d38-cb26-469b-9f12-d0d701a7b562"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating indicators for GOOGL...\n",
            "  Dropped 200 rows with NaN values for GOOGL.\n",
            "Saved Technical Indicators for GOOGL to /content/drive/MyDrive/Colab Notebooks/Data with Indicators/GOOGL_indicators.csv\n",
            "Calculating indicators for AMZN...\n",
            "  Dropped 200 rows with NaN values for AMZN.\n",
            "Saved Technical Indicators for AMZN to /content/drive/MyDrive/Colab Notebooks/Data with Indicators/AMZN_indicators.csv\n",
            "Calculating indicators for AAPL...\n",
            "  Dropped 200 rows with NaN values for AAPL.\n",
            "Saved Technical Indicators for AAPL to /content/drive/MyDrive/Colab Notebooks/Data with Indicators/AAPL_indicators.csv\n",
            "Calculating indicators for META...\n",
            "  Dropped 200 rows with NaN values for META.\n",
            "Saved Technical Indicators for META to /content/drive/MyDrive/Colab Notebooks/Data with Indicators/META_indicators.csv\n",
            "Calculating indicators for MSFT...\n",
            "  Dropped 200 rows with NaN values for MSFT.\n",
            "Saved Technical Indicators for MSFT to /content/drive/MyDrive/Colab Notebooks/Data with Indicators/MSFT_indicators.csv\n",
            "Calculating indicators for NVDA...\n",
            "  Dropped 200 rows with NaN values for NVDA.\n",
            "Saved Technical Indicators for NVDA to /content/drive/MyDrive/Colab Notebooks/Data with Indicators/NVDA_indicators.csv\n",
            "Calculating indicators for TSLA...\n",
            "  Dropped 200 rows with NaN values for TSLA.\n",
            "Saved Technical Indicators for TSLA to /content/drive/MyDrive/Colab Notebooks/Data with Indicators/TSLA_indicators.csv\n",
            "Calculating indicators for COST...\n",
            "  Dropped 200 rows with NaN values for COST.\n",
            "Saved Technical Indicators for COST to /content/drive/MyDrive/Colab Notebooks/Data with Indicators/COST_indicators.csv\n",
            "Calculating indicators for NFLX...\n",
            "  Dropped 200 rows with NaN values for NFLX.\n",
            "Saved Technical Indicators for NFLX to /content/drive/MyDrive/Colab Notebooks/Data with Indicators/NFLX_indicators.csv\n",
            "Calculating indicators for AVGO...\n",
            "  Dropped 200 rows with NaN values for AVGO.\n",
            "Saved Technical Indicators for AVGO to /content/drive/MyDrive/Colab Notebooks/Data with Indicators/AVGO_indicators.csv\n",
            "Calculating indicators for INTC...\n",
            "  Dropped 200 rows with NaN values for INTC.\n",
            "Saved Technical Indicators for INTC to /content/drive/MyDrive/Colab Notebooks/Data with Indicators/INTC_indicators.csv\n",
            "Calculating indicators for ADBE...\n",
            "  Dropped 200 rows with NaN values for ADBE.\n",
            "Saved Technical Indicators for ADBE to /content/drive/MyDrive/Colab Notebooks/Data with Indicators/ADBE_indicators.csv\n"
          ]
        }
      ]
    }
  ]
}